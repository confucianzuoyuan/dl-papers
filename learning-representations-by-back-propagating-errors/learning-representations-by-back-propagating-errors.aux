\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\abx@aux@refcontext{nty/global//global/global/global}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}正文}{3}{section.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces 一个已经学会检测输入向量镜像对称性的网络，弧上的数字表示权重，节点内的数字表示偏置。学习过程需要对 64 种可能的输入向量集进行 1,425 次遍历，每次遍历后根据累积的梯度调整权重。方程（9）中的参数值为 \(\epsilon = 0.1\) 和 \(\alpha = 0.9\)。初始权重是随机的，并均匀分布在 -0.3 到 0.3 之间。该解决方案的关键特性是，对于给定的隐藏单元，关于输入向量中点对称的权重在大小上相等但符号相反。因此，如果呈现一个对称模式，两个隐藏单元将从输入单元接收到净输入为 0，并且由于隐藏单元具有负偏置，两者都将关闭。在这种情况下，具有正偏置的输出单元将处于开启状态。请注意，中点两侧的权重比例为 1:2:4。这确保了中点上方可能出现的八种模式中的每一种都会向每个隐藏单元发送唯一的激活总和，因此只有中点下方的对称模式才能完全平衡该总和。对于所有非对称模式，两个隐藏单元都将从输入单元接收到非零激活。两个隐藏单元具有相同的权重模式但符号相反，因此对于每一个非对称模式，一个隐藏单元将开启并抑制输出单元。}}{5}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig-1}{{1}{5}{一个已经学会检测输入向量镜像对称性的网络，弧上的数字表示权重，节点内的数字表示偏置。学习过程需要对 64 种可能的输入向量集进行 1,425 次遍历，每次遍历后根据累积的梯度调整权重。方程（9）中的参数值为 \(\epsilon = 0.1\) 和 \(\alpha = 0.9\)。初始权重是随机的，并均匀分布在 -0.3 到 0.3 之间。该解决方案的关键特性是，对于给定的隐藏单元，关于输入向量中点对称的权重在大小上相等但符号相反。因此，如果呈现一个对称模式，两个隐藏单元将从输入单元接收到净输入为 0，并且由于隐藏单元具有负偏置，两者都将关闭。在这种情况下，具有正偏置的输出单元将处于开启状态。请注意，中点两侧的权重比例为 1:2:4。这确保了中点上方可能出现的八种模式中的每一种都会向每个隐藏单元发送唯一的激活总和，因此只有中点下方的对称模式才能完全平衡该总和。对于所有非对称模式，两个隐藏单元都将从输入单元接收到非零激活。两个隐藏单元具有相同的权重模式但符号相反，因此对于每一个非对称模式，一个隐藏单元将开启并抑制输出单元。}{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces 两个同构的家谱树。信息可以表示为三元组的集合，形式为<人物 1><关系><人物 2>，其中可能的关系包括 \{父亲、母亲、丈夫、妻子、儿子、女儿、叔叔、阿姨、兄弟、姐妹、侄子、侄女\}。一个分层网络可以被认为“知道”这些三元组，如果它能够在给定前两项时生成第三项。前两项通过激活两个输入单元来编码，然后网络必须通过激活代表第三项的输出单元来完成这个命题。}}{6}{figure.caption.3}\protected@file@percent }
\newlabel{fig-2}{{2}{6}{两个同构的家谱树。信息可以表示为三元组的集合，形式为<人物 1><关系><人物 2>，其中可能的关系包括 \{父亲、母亲、丈夫、妻子、儿子、女儿、叔叔、阿姨、兄弟、姐妹、侄子、侄女\}。一个分层网络可以被认为“知道”这些三元组，如果它能够在给定前两项时生成第三项。前两项通过激活两个输入单元来编码，然后网络必须通过激活代表第三项的输出单元来完成这个命题。}{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces 一个五层网络在学习后的活动状态。底层左侧有 24 个输入单元用于表示<人物1>，右侧有 12 个输入单元用于表示关系。这两组内的白色方块显示了单元的活动状态。第一组中有一个活动单元代表 Colin，第二组中有一个活动单元代表关系“有阿姨”。每组输入单元都完全连接到第二层中各自的 6 个单元组。这些组学习将人物和关系编码为分布式活动模式。第二层完全连接到中间的 12 个单元层，这些单元又连接到倒数第二层的 6 个单元。倒数第二层的活动必须激活正确的输出单元，每个输出单元代表一个特定的<人物2>。在这种情况下，有两个正确答案（用黑点标记），因为 Colin 有两个阿姨。输入单元和输出单元在空间上排列，其中英国人在一行，同构的意大利人紧接在下方。}}{6}{figure.caption.4}\protected@file@percent }
\newlabel{fig-3}{{3}{6}{一个五层网络在学习后的活动状态。底层左侧有 24 个输入单元用于表示<人物1>，右侧有 12 个输入单元用于表示关系。这两组内的白色方块显示了单元的活动状态。第一组中有一个活动单元代表 Colin，第二组中有一个活动单元代表关系“有阿姨”。每组输入单元都完全连接到第二层中各自的 6 个单元组。这些组学习将人物和关系编码为分布式活动模式。第二层完全连接到中间的 12 个单元层，这些单元又连接到倒数第二层的 6 个单元。倒数第二层的活动必须激活正确的输出单元，每个输出单元代表一个特定的<人物2>。在这种情况下，有两个正确答案（用黑点标记），因为 Colin 有两个阿姨。输入单元和输出单元在空间上排列，其中英国人在一行，同构的意大利人紧接在下方。}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces 从代表人物的 24 个输入单元到第二层中学习人物分布式表示的 6 个单元的权重。白色矩形表示兴奋性权重；黑色矩形表示抑制性权重；矩形的面积表示权重的大小。来自 12 个英国人单元的权重位于每个单元的顶部。单元 1 主要关注英国人和意大利人之间的区别，而大多数其他单元忽略了这一区别。这意味着英国人的表示与其对应的意大利人的表示非常相似。网络利用了两个家谱树之间的同构性来共享结构，因此它能够合理地从一个树推广到另一个树。单元 2 编码人物所属的世代，单元 6 编码人物来自家族的哪一支。隐藏单元捕获的特征在输入和输出编码中并不明显，因为这些编码为每个人使用单独的单元。由于隐藏特征捕获了任务领域的潜在结构，网络能够正确地推广到未训练的四个三元组上。我们训练了网络 1500 次遍历，前 20 次遍历使用 \(\epsilon = 0.005\) 和 \(\alpha =0.5\)，其余遍历使用 \(\epsilon = 0.01\) 和 \(\alpha =0.9\)。为了更容易解释权重，我们引入了“权重衰减”，在每次权重变化后将每个权重减少 0.2\%。经过长时间学习后，衰减与 \(\partial E / \partial w\) 达到平衡，因此每个权重的最终大小表明了其在减少误差中的有用性。为了防止网络需要大权重来将输出驱动到 1 或 0，如果应该开启的输出单元活动值高于 0.8，而应该关闭的输出单元活动值低于 0.2，则认为误差为零。}}{7}{figure.caption.5}\protected@file@percent }
\newlabel{fig-4}{{4}{7}{从代表人物的 24 个输入单元到第二层中学习人物分布式表示的 6 个单元的权重。白色矩形表示兴奋性权重；黑色矩形表示抑制性权重；矩形的面积表示权重的大小。来自 12 个英国人单元的权重位于每个单元的顶部。单元 1 主要关注英国人和意大利人之间的区别，而大多数其他单元忽略了这一区别。这意味着英国人的表示与其对应的意大利人的表示非常相似。网络利用了两个家谱树之间的同构性来共享结构，因此它能够合理地从一个树推广到另一个树。单元 2 编码人物所属的世代，单元 6 编码人物来自家族的哪一支。隐藏单元捕获的特征在输入和输出编码中并不明显，因为这些编码为每个人使用单独的单元。由于隐藏特征捕获了任务领域的潜在结构，网络能够正确地推广到未训练的四个三元组上。我们训练了网络 1500 次遍历，前 20 次遍历使用 \(\epsilon = 0.005\) 和 \(\alpha =0.5\)，其余遍历使用 \(\epsilon = 0.01\) 和 \(\alpha =0.9\)。为了更容易解释权重，我们引入了“权重衰减”，在每次权重变化后将每个权重减少 0.2\%。经过长时间学习后，衰减与 \(\partial E / \partial w\) 达到平衡，因此每个权重的最终大小表明了其在减少误差中的有用性。为了防止网络需要大权重来将输出驱动到 1 或 0，如果应该开启的输出单元活动值高于 0.8，而应该关闭的输出单元活动值低于 0.2，则认为误差为零。}{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces 一个同步迭代网络运行三次迭代及其等效的分层网络。迭代网络中的每个时间步对应于分层网络中的一层。分层网络的学习过程可以映射到迭代网络的学习过程中。在实现这一映射时，会出现两个复杂问题：首先，在分层网络中，前向传播过程中需要中间层单元的输出值来执行反向传播（见公式（5）和（6））。因此，在迭代网络中，需要存储每个单元的输出状态历史。其次，为了使分层网络与迭代网络等价，不同层之间的对应权重必须具有相同的值。为了保持这一特性，我们计算每组对应权重的平均梯度 \(\partial E / \partial w\)，然后按比例调整每组权重。在满足这两个条件的情况下，学习过程可以直接应用于迭代网络。这些网络可以学习执行迭代搜索或学习序列结构。}}{8}{figure.caption.6}\protected@file@percent }
\newlabel{fig-5}{{5}{8}{一个同步迭代网络运行三次迭代及其等效的分层网络。迭代网络中的每个时间步对应于分层网络中的一层。分层网络的学习过程可以映射到迭代网络的学习过程中。在实现这一映射时，会出现两个复杂问题：首先，在分层网络中，前向传播过程中需要中间层单元的输出值来执行反向传播（见公式（5）和（6））。因此，在迭代网络中，需要存储每个单元的输出状态历史。其次，为了使分层网络与迭代网络等价，不同层之间的对应权重必须具有相同的值。为了保持这一特性，我们计算每组对应权重的平均梯度 \(\partial E / \partial w\)，然后按比例调整每组权重。在满足这两个条件的情况下，学习过程可以直接应用于迭代网络。这些网络可以学习执行迭代搜索或学习序列结构。}{figure.caption.6}{}}
\abx@aux@read@bbl@mdfivesum{nobblfile}
\gdef \@abspage@last{9}
